{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOJgEH4Uvoz0SdJGWeFOhp6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jashan777/CustomDataLayerOpenAiPyBot/blob/master/Metacrafters_assessment_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Assesment for metacrafters Module 3 \n",
        "Custom-data layer on AI Companion Chatbot Backend using Python"
      ],
      "metadata": {
        "id": "jUplaZ7kawbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Custom data layer here is made from the data of **Star wars films** (skywalker saga) (1-6) films, the data (scripts) was scrapped from websites."
      ],
      "metadata": {
        "id": "V0nrL2mKdxau"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installing nessary libraries."
      ],
      "metadata": {
        "id": "lNo0Gqm2gAqo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy\n",
        "!pip install pandas\n",
        "!pip install scikit-learn\n",
        "!pip install openai"
      ],
      "metadata": {
        "id": "b0cAuVJEf_Ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now importing libraries into code "
      ],
      "metadata": {
        "id": "9JYo1vmxg5kB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import openai\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import os"
      ],
      "metadata": {
        "id": "BPT_m0bFg2zS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters for Chunk size and overlap i.e Chunk size means how many tokens a single chunk will contain in it, overlap means how many tokens will overlap between the chunks , it is done so as to remember previous context."
      ],
      "metadata": {
        "id": "3gBZP6H1hXeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CHUNK_SIZE = 600\n",
        "OVERLAP = 40"
      ],
      "metadata": {
        "id": "zB7vncTQhaTO"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Taking the OPENAI API key"
      ],
      "metadata": {
        "id": "gHAsX_yqifkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "openai.api_key = input(\"Paste your OpenAI API key here and hit enter:\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x7MVDdiaiXN3",
        "outputId": "63167e6f-0396-4ebf-c3d9-16b2e4fc384d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Paste your OpenAI API key here and hit enter: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\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating and sending chunks of the data  we have in order to obtain their embeddings , so in later stages when we ask out question it can find the most similar chunk of text which is similar to our quesition with the help of Cosine similarity."
      ],
      "metadata": {
        "id": "s3s-R6_PiqGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scripts = json.load(open(\"data/all_episodes_starwars_raw.json\", encoding='ascii')) #Opening the Raw data , The data is provided in the github repository.\n",
        "text = scripts['star-wars']['episode-1'] #taking the data from where we want to ask our questions.\n",
        "\n",
        "text_list = text.split() #Converting the Raw data into tokens \n",
        "\n",
        "chunks = [text_list[i:i+CHUNK_SIZE] for i in range(0, len(text_list), CHUNK_SIZE-OVERLAP)] #creating Chunks\n",
        "\n",
        "df = pd.DataFrame(columns=['chunk', 'gpt_raw', 'embedding']) #Creating a Dataframe \n",
        "\n",
        "for chunk in chunks: #Sending chunks to OPENAI\n",
        "    f = openai.Embedding.create(\n",
        "        model=\"text-embedding-ada-002\",\n",
        "        input=\" \".join(chunk),\n",
        "    )\n",
        "\n",
        "    df.loc[len(df.index)] = (chunk, f, np.array(f['data'][0]['embedding'])) #Inserting the Response from OPENAI into the dataframe.\n"
      ],
      "metadata": {
        "id": "GIel-gntipyg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Below code is just for checking the dataframe Skip if not nessary."
      ],
      "metadata": {
        "id": "pyxADnhXjv8h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "TEEKlZ07jwR8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we find the most similar chunk of text similar to out question we want to ask. We calculate the cosine distance from our query to each chunk, and save it in a vairable named \"context_chunk\""
      ],
      "metadata": {
        "id": "l6lNcXuvkxMg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Who is the main protaganist here ?\" #the question we want to ask\n",
        "\n",
        "f = openai.Embedding.create( #sending the question to the Embedding model \n",
        "    model=\"text-embedding-ada-002\",\n",
        "    input=query\n",
        ")\n",
        "\n",
        "query_embedding = np.array(f['data'][0]['embedding']) #putting the recived reply into the query_embedding in the form of an array.\n",
        "\n",
        "similarity = [] #initializing a list\n",
        "\n",
        "for arr in df['embedding'].values: \n",
        "    similarity.extend(cosine_similarity(query_embedding.reshape(1, -1), arr.reshape(1, -1)))  #Main code , where the magic happens , we create a cosine similarity of every chunk with our question \n",
        "\n",
        "context_chunk = chunks[np.argmax(similarity)] #Returns the indice of the maximum value , getting the chunk with the most similar embedding. \n",
        "\n",
        "query_to_send = \"CONTEXT: \" + \" \".join(context_chunk) + \"\\n\\n\" + query #creating a combination of our question with the context from where the AI should reply.\n",
        "\n",
        "response = openai.Completion.create(  #Sending the query to OPEN AI model\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt= query_to_send,\n",
        "  max_tokens=100, #used to limit the reponse generated by OPENAI model.\n",
        "  temperature=0 #the more the temprature the more the randomness in recived answer.\n",
        ")"
      ],
      "metadata": {
        "id": "b9o6Zrvmkw7d"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Query which was sended "
      ],
      "metadata": {
        "id": "2yzL1Ot6vEvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(query_to_send)"
      ],
      "metadata": {
        "id": "L363oxizvDhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Response Recived **"
      ],
      "metadata": {
        "id": "4sKoGOiFvQC0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(response['choices'][0]['text'].strip())"
      ],
      "metadata": {
        "id": "TDJCvAwNvTOJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}